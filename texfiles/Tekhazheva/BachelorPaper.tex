\documentclass[14pt]{article}

\usepackage{url}
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{gastex}
\usepackage[dvips]{graphicx}
\usepackage[ruled,section]{algorithm}
\usepackage[noend]{algorithmic}

\usepackage{pgf}
\usepackage{tikz}
\usepackage{pgfplots}

\usepackage{trees}
\usepackage{graphs}

\usepackage{setspace}
\setstretch{1.15}

\usepackage{geometry}
\geometry{top=2cm}
\geometry{bottom=2.5cm}
\geometry{left=3cm}
\geometry{right=2cm}

%\renewcommand{\tiny}{\fontsize{7}{8.4pt}\selectfont}
%\renewcommand{\scriptsize}{\fontsize{8}{11pt}\selectfont}
%\renewcommand{\footnotesize}{\fontsize{11}{13.6pt}\selectfont}
%\renewcommand{\small}{\fontsize{10}{13.6pt}\selectfont}
%\renewcommand{\normalsize}{\fontsize{12}{14.5pt}\selectfont}
%\renewcommand{\large}{\fontsize{17}{20pt}\selectfont}
%\renewcommand{\Large}{\fontsize{20}{25pt}\selectfont}
%\renewcommand{\LARGE}{\fontsize{25}{30pt}\selectfont}

\newtheorem{theorem}{Теорема}
\newtheorem{lemma}{Лемма}
\newtheorem{example}{Пример}[section]
\newtheorem{claim}{Утверждение}[section]
\newtheorem{corollary}{Следствие}[section]
\newtheorem{proposition}{Предложение}[section]

\floatname{algorithm}{Алгоритм}
\renewcommand{\algorithmicrequire}{\textbf{Вход:}}
\renewcommand{\algorithmicensure}{\textbf{Выход:}}
\renewcommand{\algorithmicreturn}{\textbf{Вернуть}}

\newcommand{\slp}[1]{\mathbb{#1}}

\newenvironment{refTheorem}[2][Теорема]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}



\begin{document}
\large
\begin{singlespace}
\tableofcontents
\newpage
\end{singlespace}


\section{Введение}

Во многих современных задачах возникает потребность в обработке больших объемов данных. Это связано с быстро растущим объемом
доступной информации (например в сети Интернет).
Среди существующего многообразия алгоритмов поиска и обработки данных часто оказывается сложно найти метод,
подходящий для практического применения. Это связано с тем, что каждый из существующих алгоритмов накладывает некие ограничения на данные,
с которыми он может работать. Поэтому не всегда возможно найти готовый алгоритм, который будет подходить для решения новой задачи.

Из-за потребности в решении задач со специфическими ограничениями, стали появляться классы алгоритмов
с характерными особенностями в работе. Например, существует класс алгоритмов, которые эффективно работают с кэшем процессора и таким образом дают хорошую скорость работы алгоритма (класс cache-oblivious). Также можно вспомнить о классе IO-efficient алгоритмов --- они призваны обрабатывать объемы данных, которые невозможно сохранить в оперативной памяти, и поэтому сильно зависят от способа работы с жестким диском.

В конце XX века стала развиваться менее очевидная идея обработки больших объемов данных, которая заключается в том, что данные можно хранить в сжатом виде.
При этом, если способ сжатия имеет хорошую структуру, это позволит обрабатывать текст без предварительной распаковки. Этот подход позволяет сэкономить место для хранения данных и уменьшить объемы входных и выходных данных для решаемой задачи. Такие алгоритмы называются алгоритмами над сжатыми представлениями.

Существуют разные методы сжатия данных: контекстное сжатие \cite{Welch} \cite{LZ}, статистическое сжатие \cite{Huffman}, сжатие с помощью антисловарей \cite{anti} и т. д. Понятно, что не каждый способ сжатия данных порождает структуру, поддерживающую возможность выполнять поисковые запросы.
В работе рассматривается один из самых популярных сегодня методов~--- метод сжатия с помощью прямолинейных
программ (straight line programs, \cite{Ritter}).
Прямолинейные программы являются удобной абстракцией, позволяющей описывать различные способы сжатия данных. В частности, известно, что 
сжатие с помощью алгоритмов типа Лемпеля--Зива почти эквивалентно прямолинейной программе. Более точно~--- существует эффективный алгоритм,
позволяющий по данному кодированию типа Лемпеля--Зива построить прямолинейную программу кодирующую тот же текст, причем длина кода увеличится не более чем в $O(log|T|)$ раз, где $|T|$~--- длина закодированной строки \cite{Ritter}.
Это позволяет рассматривать только алгоритмы над прямолинейными программами, что гораздо удобнее из-за простой структуры ПП.

\emph{Прямолинейная программа (ПП)}~--- это контекстно-свободная грамматика, порождающая ровно одну строку.
Правила этой грамматики могут иметь один из двух видов $X_i \to a$ (терминальные символы) и $X_i \to X_j X_k$, где $i > j, k$.

Мы подробнее рассмотрим понятие прямолинейной программы в одной из следующих глав. 

%\section{Постановка задачи и структура работы}

Одной из самых распространенных задач, связанных с получением информации о тексте~--- поиск образца в тексте.
Эта задача --- одна из простейших, а потому встречается на практике крайне часто (например, в работе поисковых машин, сборе статистики и т. д.). 

Задача проверки равенства двух сжатых строк была решена в 1994 году в работе \cite{1994} за время $O(n^4)$, в 1997 году появился алгоритм поиска образца в строке, имеющий сложность $O(n^2 m^2)$, где $n$ и $m$~--- размеры прямолинейных программ, порождающих образец и текст соответственно \cite{1997}. В нашей работе рассматривается алгоритм, работающий за время $O(n^2 m)$, предложенный Ю. Лифшицем
в работе \cite{Lifshits}.

В статье \cite{Lifshits} доказывается теоретическая асимптотическая оценка времени работы алгоритма.
Однако, на практике скорость работы алгоритма может зависеть от деталей реализации. Также, при практическом применении важна не только асимптотика, но и фактическая скорость работы алгоритма на реальных данных. 
Кроме того, различные алгоритмы могут показывать различный результат в зависимости от особенностей входных данных (например, для текстов с маленьким алфавитом или текстов имеющих специальную структуру). 

В этой работе мы рассматриваем следующие вопросы:
\begin{itemize}
\item Насколько эффективен алгоритм Лифшица на практике? Удается ли достичь теоретически предсказываемой эффективности?
\item Как можно увеличить производительность алгоритма на практике?
\item Как меняется эффективность алгоритма в зависимости от исходного текста, на котором была построена ПП?
\item В какой степени алгоритм Лифшица допускает распараллеливание?
\end{itemize}

Структура работы такова: во второй главе вводятся основные определения, касающиеся прямолинейных программ и алгоритма Лифшица; третья глава посвящена краткому изложению алгоритма; в четвертой главе приводятся результаты практических тестов алгоритма и описывается ход исследования; в пятой главе описаны основные выводы.

\section{Основные определения}
%Основные определения
%Тексты и подстроки
Будем рассматривать тексты над конечным алфавитом $\Sigma$. 

\emph{Прямолинейная программа (ПП)}~--- это контекстно-свободная грамматика, порождающая ровно одну строку.
Правила этой грамматики могут иметь один из двух видов $X_i \to a$ (терминальные символы) и $X_i \to X_j X_k$, где $i > j, k$.

Строка, которую выводит прямолинейная программа, относится к последнему нетерминалу $X_n$. 

{\bf Пример}: Рассмотрим ПП, которая порождает текст <<$abaababaabaab$>>:

\begin{center}
$X_1 \to a, X_2 \to b, X_3 \to X_1\cdot X_2, X_4 \to X_3\cdot X_1,$

$X_5 \to X_4\cdot X_3, X_6 \to X_5\cdot X_4, X_7 \to X_6\cdot X_5$
\end{center}

Дерево вывода этой грамматики изображено на рис.\,\ref{slp_example}

\begin{figure}[h]
\begin{center}
\begin{pgfpicture}{0cm}{0cm}{8.5cm}{5cm}
        \pgfputat{\pgfxy(0,0)}{\pgfbox[left,center]{$a$}}
        \pgfputat{\pgfxy(0.7,0)}{\pgfbox[left,center]{$b$}}
        \pgfputat{\pgfxy(1.4,0)}{\pgfbox[left,center]{$a$}}
        \pgfputat{\pgfxy(2.1,0)}{\pgfbox[left,center]{$a$}}
        \pgfputat{\pgfxy(2.8,0)}{\pgfbox[left,center]{$b$}}
        \pgfputat{\pgfxy(3.5,0)}{\pgfbox[left,center]{$a$}}
        \pgfputat{\pgfxy(4.2,0)}{\pgfbox[left,center]{$b$}}
        \pgfputat{\pgfxy(4.9,0)}{\pgfbox[left,center]{$a$}}
        \pgfputat{\pgfxy(5.6,0)}{\pgfbox[left,center]{$a$}}
        \pgfputat{\pgfxy(6.3,0)}{\pgfbox[left,center]{$b$}}
        \pgfputat{\pgfxy(7,0)}{\pgfbox[left,center]{$a$}}
        \pgfputat{\pgfxy(7.7,0)}{\pgfbox[left,center]{$a$}}
        \pgfputat{\pgfxy(8.4,0)}{\pgfbox[left,center]{$b$}}

        \pgfxyline(0.1,0.2)(0.1, 0.6)
        \pgfxyline(0.8,0.2)(0.8, 0.6)
        \pgfxyline(1.5,0.2)(1.5, 0.6)
        \pgfxyline(2.2,0.2)(2.2, 0.6)
        \pgfxyline(2.9,0.2)(2.9, 0.6)
        \pgfxyline(3.6,0.2)(3.6, 0.6)
        \pgfxyline(4.3,0.2)(4.3, 0.6)
        \pgfxyline(5,0.2)(5, 0.6)
        \pgfxyline(5.7,0.2)(5.7, 0.6)
        \pgfxyline(6.4,0.2)(6.4, 0.6)
        \pgfxyline(7.1,0.2)(7.1, 0.6)
        \pgfxyline(7.8,0.2)(7.8, 0.6)
        \pgfxyline(8.5,0.2)(8.5, 0.6)

        \pgfputat{\pgfxy(-0.1,0.75)}{\pgfbox[left,center]{$X_1$}}
        \pgfputat{\pgfxy(0.6,0.75)}{\pgfbox[left,center]{$X_2$}}
        \pgfputat{\pgfxy(1.3,0.75)}{\pgfbox[left,center]{$X_1$}}
        \pgfputat{\pgfxy(2,0.75)}{\pgfbox[left,center]{$X_1$}}
        \pgfputat{\pgfxy(2.7,0.75)}{\pgfbox[left,center]{$X_2$}}
        \pgfputat{\pgfxy(3.4,0.75)}{\pgfbox[left,center]{$X_1$}}
        \pgfputat{\pgfxy(4.1,0.75)}{\pgfbox[left,center]{$X_2$}}
        \pgfputat{\pgfxy(4.8,0.75)}{\pgfbox[left,center]{$X_1$}}
        \pgfputat{\pgfxy(5.5,0.75)}{\pgfbox[left,center]{$X_1$}}
        \pgfputat{\pgfxy(6.2,0.75)}{\pgfbox[left,center]{$X_2$}}
        \pgfputat{\pgfxy(6.9,0.75)}{\pgfbox[left,center]{$X_1$}}
        \pgfputat{\pgfxy(7.6,0.75)}{\pgfbox[left,center]{$X_1$}}
        \pgfputat{\pgfxy(8.3,0.75)}{\pgfbox[left,center]{$X_2$}}

        \pgfxyline(0.1,1)(0.1, 1.2)
        \pgfxyline(0.8,1)(0.8, 1.2)
        \pgfxyline(0.1,1.2)(0.45, 1.5)
        \pgfxyline(0.8,1.2)(0.45, 1.5)
        \pgfputat{\pgfxy(0.3,1.65)}{\pgfbox[left,center]{$X_3$}}

        \pgfxyline(2.2,1)(2.2, 1.2)
        \pgfxyline(2.9,1)(2.9, 1.2)
        \pgfxyline(2.2,1.2)(2.55,1.5)
        \pgfxyline(2.9,1.2)(2.55,1.5)
        \pgfputat{\pgfxy(2.4,1.65)}{\pgfbox[left,center]{$X_3$}}

        \pgfxyline(3.6,1)(3.6, 1.2)
        \pgfxyline(4.3,1)(4.3, 1.2)
        \pgfxyline(3.6,1.2)(3.95, 1.5)
        \pgfxyline(4.3,1.2)(3.95, 1.5)
        \pgfputat{\pgfxy(3.8,1.65)}{\pgfbox[left,center]{$X_3$}}

        \pgfxyline(5.7,1)(5.7, 1.2)
        \pgfxyline(6.4,1)(6.4, 1.2)
        \pgfxyline(5.7,1.2)(6.05, 1.5)
        \pgfxyline(6.4,1.2)(6.05, 1.5)
        \pgfputat{\pgfxy(5.9,1.65)}{\pgfbox[left,center]{$X_3$}}

        \pgfxyline(7.8,1)(7.8, 1.2)
        \pgfxyline(8.5,1)(8.5, 1.2)
        \pgfxyline(7.8,1.2)(8.15, 1.5)
        \pgfxyline(8.5,1.2)(8.15, 1.5)
        \pgfputat{\pgfxy(8,1.65)}{\pgfbox[left,center]{$X_3$}}

        \pgfxyline(1.5, 1)(1.5, 1.9)
        \pgfxyline(0.45, 1.9)(0.97, 2.3)
        \pgfxyline(1.5, 1.9)(0.97, 2.3)
        \pgfputat{\pgfxy(0.82, 2.45)}{\pgfbox[left,center]{$X_4$}}

        \pgfxyline(5, 1)(5, 1.9)
        \pgfxyline(3.95, 1.9)(4.47, 2.3)
        \pgfxyline(5, 1.9)(4.47, 2.3)
        \pgfputat{\pgfxy(4.32, 2.45)}{\pgfbox[left,center]{$X_4$}}

        \pgfxyline(7.1,1)(7.1, 1.9)
        \pgfxyline(6.05,1.9)(6.57, 2.3)
        \pgfxyline(7.1, 1.9)(6.57, 2.3)
        \pgfputat{\pgfxy(6.42,2.45)}{\pgfbox[left,center]{$X_4$}}

        \pgfxyline(2.55,1.85)(2.55, 2.65)
        \pgfxyline(0.97, 2.65)(1.76, 3.05)
        \pgfxyline(2.55, 2.65)(1.76, 3.05)
        \pgfputat{\pgfxy(1.61, 3.2)}{\pgfbox[left,center]{$X_5$}}

        \pgfxyline(8.15, 1.85)(8.15, 2.65)
        \pgfxyline(6.57,2.65)(7.36, 3.05)
        \pgfxyline(8.15, 2.65)(7.36, 3.05)
        \pgfputat{\pgfxy(7.21,3.2)}{\pgfbox[left,center]{$X_5$}}

        \pgfxyline(4.47,2.65)(4.47, 3.4)
        \pgfxyline(1.76,3.4)(3.11, 3.8)
        \pgfxyline(4.47, 3.4)(3.11, 3.8)
        \pgfputat{\pgfxy(2.96,3.95)}{\pgfbox[left,center]{$X_6$}}

        \pgfxyline(7.36,3.4)(7.36, 4.15)
        \pgfxyline(3.11,4.15)(5.23, 4.75)
        \pgfxyline(7.36, 4.15)(5.23, 4.75)
        \pgfputat{\pgfxy(5.08, 4.9)}{\pgfbox[left,center]{$X_7$}}

  %      \pgfputat{\pgfxy(-2,-0.7)}{\pgfbox[left,center]{{\bf Рисунок 1.} Дерево вывода грамматики, порождающей <<$abaababaabaab$>>}}
\end{pgfpicture}
\end{center}
\caption{Дерево вывода слова <<abaababaabaab>>}
\label{slp_example}
\end{figure}

Каждый нетерминал грамматики порождает некоторую подстроку исходной строки. Например, из нетерминала $X_5$, в примере приведенном выше, выводится подстрока $abaab$.

Для удобства изложения мы будем обозначать символом $X$ как прямолинейную программу, так и порождаемую ею строку. Символы $X_i$ обозначают отдельные нетерминалы контекстно-свободной грамматики $X$ (или строки, соответствующие этим нетерминалам). 

Символ $|X|$ означает количество символов в строке, порождаемой прямолинейной программой $X$.

Для изложения алгоритма Лифшица нам потребуется ввести некоторые термины. 

\begin{itemize}

\item \emph{Позицией} в строке называется место между любыми двумя соседними символами, а так же перед первым и за последним символами строки.
Таким образом, в строке из $n$ символов есть позиции $0,1,\dots,n$.

\item Будем говорить, что подстрока \emph{касается} некой позиции в тексте, если эта позиция лежит внутри или на границе подстроки.

\item Термин \emph{вхождение} будет использоваться для обозначения начальной позиции подстроки в тексте. 

\item Пусть строка порождается грамматикой с нетерминалами $X_1, \dots, X_n$. Будем называть \emph{позицией разреза} (или просто \emph{разрезом})  
начальные позиции для терминальных строк и позиции на стыке двух правил. 

\end{itemize}

В примере из рис.\,\ref{slp_example} разрез строки <<$abaab$>>, выводящейся из нетерминала $X_5$ находится на 
третьей позиции~--- <<$aba|ba$>>. Есть два вхождения строки <<$ab$>> в строку <<$ababa$>>~--- на позициях $1$ и $3$, причем второе касается разреза, а первое - нет. Строка <<$ba$>> так же входит в <<$ababa$>> дважды, причем оба вхождения касаются разреза.

\section{Алгоритм Лифшица}
\subsection{Общая схема}
Мы приведем краткое описание алгоритма Лифшица, останавливаясь подробно лишь на деталях, важных для нашего анализа алгоритма. Более полное описание алгоритма можно найти в работе \cite{Lifshits}.
             
Алгоритм получает на вход две прямолинейные программы $T$ и $P$, выводящие текст и образец, который нужно найти в этом тексте. 
Результатом работы является список всех вхождений образца в текст.

Заметим, что хранить позиции вхождений $P$ в $T$ в явном виде не представляется возможным, поскольку при достаточно большом тексте их может оказаться слишком много. Например, если искать строку вида $a^k$ в строке вида $a^p$, число вхождений будет экспоненциально относительно размеров сжатого текста. Поэтому, хранить эту информацию следует в сжатом виде. Авторы работ \cite{Lifshits} и \cite{1997} используют для хранения информации о позициях вхождений арифметические прогрессии, основываясь при этом на следующем теоретическом факте:

\begin{lemma} \label{main}
Вхождения образца $P$ в текст $T$, касающиеся некоторой фиксированной позиции, образуют одну арифметическую прогрессию.
\end{lemma}

Алгоритм Лифшица основан на построении таблицы арифметических прогрессий, которая определяется следующим образом:

\begin{itemize}
\item Для всех  пар чисел $1 \leqslant i \leqslant m,\, 1 \leqslant j \leqslant n$ значение $A[i,j]$ задает арифметическую прогрессию вхождений 
$P_i$ в $T_j$, касающихся разреза $T_j$.
\end{itemize}

Заметим, что хранить арифметическую прогрессию можно в виде трех чисел --- начального элемента, разности и количества
элеменов в прогрессии.

В работе \cite{Lifshits} сформулированы и доказаны следующие утверждения:
\begin{claim} 
Используя таблицу арифметических прогрессий можно решить задачу поиска подстроки в строке за $O(n)$.
\end{claim}
\begin{claim}
Вычислить таблицу арифметических прогрессий можно за $O(n^2m)$ с помощью метода динамического программирования.
\end{claim}

Напомним, что здесь $n$ и $m$~--- размеры прямолинейных программ, порождающих образец и текст соответственно.

Построение таблицы арифметических прогрессий состоит из трех этапов.
\begin{enumerate}
\item Сбор вспомогательной информации: длин и разрезов строк, выводимых из всех правил грамматики.
\item Вычисление значений ячеек таблицы арифметических прогрессий, которые соответствуют однобуквенным текстам.
\item Вычисление оставшихся ячеек таблицы арифметических прогрессий в порядке от меньшего(по длине) образца к большему и от меньшего текста к большему.
\end{enumerate}
Шаги 1 и 2 достаточно просты. Остановимся подробнее на описании третьего шага.

Вычисление значения в ячейке $A[i, j]$ для нетерминальных строк происходит следующим образом. Пусть ПП $P$ содержит правило 
$P_i \to P_f P_s$. Будем для удобства считать, что длина строки $P_f$ не меньше, чем длина строки $P_s$.  

\begin{itemize}
\item[(a)] Найдем все вхождения $P_f$ в $T_j$, которые могут быть началом интересующего нас вхождения.
\item[(b)] Найдем вхождения $P_s$ в $T_j$, которые начинаются в позициях концов вхождений $P_f$.
\item[(c)] Пересечем полученные множества вхождений и запишем их в виде одной арифметической прогрессии вхождений $P_i$ в $T_j$.
\end{itemize}

Для поиска $P_f$ в $T_j$ будем использовать вспомогательную процедуру\\
\texttt{LocalSearch(f, j, $\alpha$, $\beta$)}, работа которой будет описана ниже. 
Эта процедура находит все вхождения $P_f$ в $T_j$ на отрезке $[\alpha, \beta]$.
Можно показать, что эти вхождения записываются в виде не более чем двух арифметических прогрессий.
Для того, чтобы процедура работала корректно требуется чтобы выполнялось неравенство 

\begin{equation} \beta-\alpha < 3 |P_f|. \label{beta-alpha} \end{equation}
 
Чтобы найти все вхождения $P_f$ которые потенциально могут быть началом вхождения $P_i$, касающегося разреза,
запустим процедуру поиска\\
\texttt{LocalSearch($f$, $j$, $r$ - $|P_i|$, $r$ + $|P_f|$)}, где $r$ --- позиция разреза в $T_j$.
Заметим, что неравенство (\ref{beta-alpha}) выполняется, поскольку мы рассматриваем случай $|P_f| \geqslant |P_s|$.
Обратный случай обрабатывается аналогичным образом. 


После того как интересующие нас вхождения $P_f$ в $T_j$ найдены, нужно для каждого из них проверить, верно ли
что существует вхождение $P_s$, начинающееся в позиции конца данного вхождения. Эта проверка также осуществляется
с помощью вспомогательной процедуры \texttt{LocalSearch}.

Отметим, что алгоритм Лифшица позволяет проверить все вхождения $P_f$, образующие арифметическую прогрессию, не рассматривая
каждое вхождение отдельно. Это позволяет существенно уменьшить количество обращений к функции \texttt{LocalSearch} 
на этапе $(b)$.

%Стоит отметить, что рассматривая вхождения $P_f$, образующие арифметическую прогрессию, мы можем сделать эту проверку
%лишь для некоторых членов прогрессии. Подробнее у Лифшица или описать?
 
Позиции вхождений $P_f$, для которых проверка прошла успешно, образуют интересующее нас множество 
вхождений $P_i$ в $T_j$, касающихся разреза. 
По лемме \ref{main} эти позиции будут образовывать одну арифметическую прогрессию.


\subsection{Процедура Localsearch}

\texttt{LocalSearch($f$, $j$, $\alpha$, $\beta$)} работает следующим образом
Вхождения $P_f$ в $T_j$, которые касаются разреза, уже найдены и записаны в ячейке $A[f, j]$ таблицы арифметических прогрессий, нужно лишь выбрать те из них,
что находятся внутри отрезка $[\alpha, \beta]$.

После того как такие вхождения найдены остается найти вхождения $P_f$ в $T_j$, которые не касаются разреза. Таким вхождениям соответствуют вхождения $P_f$ в строки $T_{j_1}$ и $T_{j_2}$ (мы считаем, что правило для $T_j$ имеет вид $T_j \to T_{j_1}\cdot T_{j_2}$).
Для того чтобы найти их запустим процедуру поиска рекурсивно для каждой из строк $T_{j_1}$ и $T_{j_2}$ на нужных подотрезках.

В результате получим множество позиций, которые образуют не более чем две арифметические прогрессии \cite{Lifshits}.

Процедура \texttt{LocalSearch} работает за время $O(j)$.

\subsection{Пример работы}

Рассмотрим работу алгоритма на примере. Пусть текст <<$ababa$>> представлен следующей ПП:

\begin{center}
$T_1 \to a, T_2 \to b, T_3 \to T_2\cdot T_1, T_4 \to T_1\cdot T_3, T_5 \to T_4\cdot T_3$
\end{center}

Будем искать в этом тексте образец <<$aba$>>

\begin{center}
$P_1 \to a, P_2 \to b, P_3 \to P_1\cdot P_2, P_4 \to P_3\cdot P_1$
\end{center}

Тройка $(f, d, s)$ в ячейке таблицы означает арифметическую прогрессию с началом в
позиции $f$, разностью $d$ и состоящую из $s$ элементов.
Для простоты будем считать, что у одноэлементных арифметических прогрессий $d = 1$.
Символ <<$-$>> в ячейке $APTable[i, j]$ означает отсутствие вхождений $P_i$ в $T_j$, касающихся разреза. 

После вычисления ячеек таблицы, соответствующих однобуквенным текстам, таблица арифметических прогрессий будет выглядеть следующим образом:

\begin{figure}[H]
    \begin{center}
        \begin{tabular}{ | c | c | c | c | c | c |}

        \hline
              & $T_1$ & $T_2$ & $T_3$ & $T_4$ & $T_5$ \\
              & <<$a$>> & <<$b$>> & <<$ba$>> & <<$aba$>> & <<$ababa$>> \\      
        \hline
        $P_1$ <<$a$>> & (1, 1, 1) & - & (2, 1, 1) & (1, 1, 1) & (3, 1, 1) \\
        \hline
        $P_2$ <<$b$>> & - & (1, 1, 1) & (1, 1, 1) & (2, 1, 1) & (4, 1, 1) \\
        \hline
        $P_3$ <<$ab$>> & - & - & & &\\
        \hline
        $P_4$ <<$aba$>> & - & - & & &\\
        \hline
        \end{tabular}
    \end{center}
    \caption{Вычислены значения ячеек, соответствующих однобуквеннм текстам}
    \label{ex1}
\end{figure}

На следующем этапе построения таблицы будут заполнены остальные ячейки.
Мы подробнее рассмотрим процесс вычисление значения в ячейке $APTable[4, 5]$. Она соответствует вхождениям образца
<<$aba$>> в текст <<$ababa$>>.
Перед началом вычисления значения этой ячейки таблица выглядит так:

\begin{figure}[H]
    \begin{center}
        \begin{tabular}{ | c | c | c | c | c | c |}

        \hline
              & $T_1$ & $T_2$ & $T_3$ & $T_4$ & $T_5$ \\
              & <<$a$>> & <<$b$>> & <<$b|a$>> & <<$a|ba$>> & <<$aba|ba$>> \\      
        \hline
        $P_1$ <<$a$>> & (1, 1, 1) & - & (2, 1, 1) & (1, 1, 1) & (3, 1, 1) \\
        \hline
        $P_2$ <<$b$>> & - & (1, 1, 1) & (1, 1, 1) & (2, 1, 1) & (4, 1, 1) \\
        \hline
        $P_3$ <<$ab$>> & - & - & - & (1, 1, 1) & (3, 1, 1)\\
        \hline
        $P_4$ <<$aba$>> & - & - & - & (1, 1, 1) & \\
        \hline
        \end{tabular}
    \end{center}
    \caption{Вид таблицы перед вычислением $APTable[4, 5]$}
    \label{ex2}
\end{figure}

Образец <<$aba$>> получен из правила $P_4 \to P_3\cdot P_1$, где из $P_3$ выводится строка <<$ab$>>,
а из $P_1$ --- строка <<$a$>>. Так как $|P_3| > |P_1|$ сначала будем искать в тексте вхождения $P_3$.
Для этого запустим процедуру \texttt{LocalSearch($3, 5, [1, 5]$)}.
Рассмотрим процесс выполнения этой процедуры.

Сначала получим вхождения $P_3$, которые касаются разреза $T_5$. Чтобы получить арифметическую прогрессию,
соответствующую этим вхождениям, нужно просто обратиться к ячейке $APTable[3, 5]$, которая была вычислена
ранее. Таким образом, получаем прогрессию $(3, 1, 1)$. Далее, из этой прогрессии удаляем элементы соответствующие вхождениям $P_3$, которые не содержатся в отрезке $[1, 5]$. 
В данном случае таких элементов нет, и прогрессия остается неизменной.

Далее следует найти вхождения $P_3$ в $T_5$ на отрезке $[1, 5]$, не касающиеся разреза.
Для этого нужно рекурсивно запустить процедуру \texttt{LocalSearch} для образца $P_3$ и каждого из текстов $T_4$ и $T_3$, так как $T_5$ получено из правила $T_5 \to T_4\cdot T_3$. При этом границы отрезка поиска также будут меняться.

Рекурсивные вызовы будут выглядеть следующим образом: \texttt{LocalSearch($3, 4, [1, 3]$)} и 
\texttt{LocalSearch($3, 3, [1, 2]$)}.

Первый вызов найдет арифметическую прогрессию $(1, 1, 1)$ из ячейки $APTable[3, 4]$. В результате второго вызова новых
вхождений не найдется.
Дальнейших рекурсивных вызовов также не последует из-за того, что отрезки поиска станут короче образца, который мы ищем.

Таким образом, найдены две арифметические прогрессии вхождений $P_3$ в $T_5$, которые
объединяются в одну $(1, 2, 2)$.
Для каждого из вхождений теперь нужно проверить, можно ли дополнить его до вхождения $P_4$ в $T_5$, то есть
существует ли вхождение $P_1$, начинающееся в позиции следующей за концом вхождения $P_3$.
Эти проверки так же производятся с помощью процедуры \texttt{LocalSearch}. Вызовы выглядят так:
\texttt{LocalSearch($1, 5, [3, 3]$)} и \texttt{LocalSearch($1, 5, [5, 5]$)}

В итоге получаем $APTable[4, 5] = (1, 2, 2)$

\section{Практические исследования}
\subsection{Особенности реализации}

Все практические исследования выполнены с помощью программ на языке Java, которые находятся в свободном доступе
по ссылке \url{https://code.google.com/p/overclocking}. 
Прямолинейные программы, порождающие текст и образец строились с помощью алгоритма, описанного в статье \cite{usu}, который
является модификацией алгоритма Риттера \cite{Ritter}. Этот алгоритм строит ПП, деревья выводов которых являются сбалансированными. 
За счет этого достигается лучшая степень сжатия.

Первая проблема, с которой мы столкнулись при попытке запуска алгоритма Лифшица на практике, заключается в том, что для его работы требуется заполнять таблицу арифметических прогрессий, размер которой $n\times m$, где $n$ ---  размер прямолинейной программы $P$ (то есть количество нетерминальных символов в этой параллельной программе), а $m$ --- размер параллельной программы $T$. В каждой ячейке таблицы хранится три целых числа, занимающие $12$ байт без учета накладных расходов на создание объекта. Если $T$ содержит $10^5$ правил
(этому соответствует ДНК размером около 1,5 мегабайт), поиск образца размером $10^4$ требует около $12$ гигабайт оперативной памяти только для хранения таблицы арифметических прогрессий. То есть даже при относительно небольших размерах сжатых текста и образца хранить таблицу в памяти становится проблематично.

Однако, хранить все ячейки таблицы в течении всего времени работы алгоритма необязательно. Чтобы получить информацию о вхождении образца в текст, достаточно последней строки таблицы. Остальные строки нужны лишь для промежуточных вычислений.

Так, для вычисления ячейки $APTable[i, j]$ нужно чтобы уже были вычислены ячейки $APTable[f, 1..j]$, 
$APTable[s, 1..j]$. Здесь мы считаем, что правило $P_i$ имеет вид $P_i \to P_f P_s$.
Это позволяет построить граф зависимостей строк таблицы и хранить очередную строку только до тех пор, пока она нужна для вычислений.

Также, была выдвинута гипотеза о том, что чем больше размер используемого алфавита, тем меньше соответствия будет между текстом и образцом и, соответственно, больше пустых ячеек в таблице арифметических прогрессий.
Для подтверждения этой гипотезы была посчитана степень разреженности таблицы для текстов над алфавитом размера $4$ и $26$.

\begin{figure}[h]
    \begin{center}
    \begin{tabular}{ | c | c | c | c |}
        \hline
          & Total & Empty & Percentage \\
        \hline
        $T Size = 14463$ $P Size = 14463$ & $209178369$ & $208745588$ & $99.79\%$\\
        \hline
        $T Size = 14463$ $P Size = 2283$ & $48928329$ & $48644839$ & $99.42\%$\\
        \hline
        $T Size = 14463$ $P Size = 1841$ & $26626383$ & $26383393$ & $99.09\%$\\
        \hline
        $T Size = 14463$ $P Size = 1019$ & $14737797$ & $14536063$ & $98.63\%$\\
        \hline
        $T Size = 14463$ $P Size = 465$ & $6725295$ & $6572425$ & $97.72\%$\\
        \hline
        $T Size = 14463$ $P Size = 266$ & $3847158$ & $3721341$ & $96.72\%$\\
        \hline
    \end{tabular}
    \end{center}
    \caption{Разреженность таблицы для четырехбуквенного алфавита}
    \label{four_letter_emptyness}
\end{figure}

\begin{figure}[h]
    \begin{center}
    \begin{tabular}{ | c | c | c | c |}
        \hline
            & Total & Empty & Percentage \\
        \hline
        $T Size = 35133$ $P Size = 35133$ & $1234327689$ & $1234013855$ & $99.97\%$\\
        \hline
        $T Size = 35253$ $P Size = 7694$ & $271236582$ & $271040921$ & $99.92\%$\\
        \hline
        $T Size = 35225$ $P Size = 4147$ & $146078075$ & $145899926$ & $99.88\%$\\
        \hline
        $T Size = 35243$ $P Size = 2307$ & $81305601$ & $81145099$ & $99.80\%$\\
        \hline
        $T Size = 35176$ $P Size = 1060$ & $37286560$ & $37161795$ & $99.67\%$\\
        \hline
        $T Size = 35178$ $P Size = 580$ & $20403240$ & $20299706$ & $99.49\%$\\
        \hline
    \end{tabular}
    \end{center}
    \caption{Разреженность таблицы для 26-буквенного алфавита}
    \label{26_letter_emptyness}
\end{figure}

Из приведенных данных видно, что гипотеза подтверждается на практике.
Это позволяет вообще отказаться от хранения таблицы как таковой и хранить лишь ячейки, содержащие непустые арифметические прогрессии, например, с помощью хеш-таблиц или списков.

\subsection{Исследование эффективности алгоритма}

Была выдвинута гипотеза о том, что на текстах над маленьким алфавитом алгоритм Лифшица может показать более эффективную работу, за счет того что структуры прямолинейных программ, выводящих текст и образец могут оказаться более похожими, чем для больших алфавитов. Поэтому для тестирования алгоритма был выбран класс текстов ДНК. Помимо того, что такие тексты отличаются большим объемом и строятся над алфавитом всего из четырех букв, эффективные методы работы с ними могут оказаться полезны в различных работах из области биоинформатики.
Используемые нами ДНК были взяты из открытого банка Японии (\url{http://www.ddbj.nig.ac.jp/}).

В результате была собрана статистика по следующим текстам
\begin{itemize}
\item Случайные тексты над 26-буквенным алфавитом
\item Случайные тексты над 4-буквенным алфавитом
\item Последовательности ДНК
\end{itemize}

Ниже приведены графики зависимости времени работы алгоритма от длины образца для трех упомянутых типов текстов. Длина текста внутри одного графика фиксирована.

\begin{figure}[H]
    \begin{center}
       \begin{tikzpicture}
        \begin{axis}[
            legend pos = north west,
            xlabel=$Pattern length$,
            ylabel=$Time(sec)$,
            scaled x ticks = false]
        \addplot[smooth,mark=*,blue] 
            plot coordinates {
                (13457, 3552)
                (6728, 1160)
                (2691, 422)
                (1345, 240)
                (672, 138)
                (269, 63)
                (134, 39)
            };
        \addlegendentry{DNA}

        \addplot[smooth,color=red,mark=x]
            plot coordinates {
                (15000, 3615)
                (7500, 2888)
                (3000, 1101)
                (1500, 502)
                (750, 213)
                (300, 67)
                (150, 27)
            };
        \addlegendentry{random 4-letter}

        \addplot[smooth,color=black,mark=+]
            plot coordinates {
                (15000, 7297)
                (7500, 2717)
                (3000, 1105)
                (1500, 550)
                (750, 263)
                (300, 100)
                (150, 48)
            };
        \addlegendentry{random 26-letter}

        \end{axis}
        \end{tikzpicture}
    \end{center}
    \caption{Длина текста около 1500000 символов}
    \label{dna_time_stats}
\end{figure}

\begin{figure}[H]
      \begin{center}
       \begin{tikzpicture}
        \begin{axis}[
            legend pos = north west,
            xlabel=$Pattern length$,
            ylabel=$Time(sec)$]
        \addplot[smooth,mark=*,blue] 
            plot coordinates {
                (7729, 870)
                (3864, 405)
                (1545, 143)
                (772, 84)
                (386, 39)
                (154, 16)
                (77, 8)
            };
        \addlegendentry{DNA}

        \addplot[smooth,color=red,mark=x]
            plot coordinates {
                (7500, 1060)
                (3750, 296)
                (1500, 155)
                (750, 55)
                (375, 28)
                (150, 13)
                (75, 7)
            };
        \addlegendentry{random 4-letter}

        \addplot[smooth,color=black,mark=+]
            plot coordinates {
                (7500, 1190)
                (3750, 598)
                (1500, 239)
                (750, 110)
                (375, 54)
                (150, 22)
                (75, 11)
            };
        \addlegendentry{random 26-letter}

        \end{axis}
        \end{tikzpicture}
    \end{center}
    \caption{Длина текста около 750000 символов}
    \label{dna_time_stats1}
\end{figure}

\begin{figure}[H]
    \begin{center}
       \begin{tikzpicture}
        \begin{axis}[
            legend pos = north west,
            xlabel=$Pattern length$,
            ylabel=$Time(sec)$]
        \addplot[smooth,mark=*,blue] 
            plot coordinates {
                (5072, 258)
                (2536, 106)
                (1014, 49)
                (507, 25)
                (253, 12)
                (101, 4)
                (50, 2)

            };
        \addlegendentry{DNA}

        \addplot[smooth,color=red,mark=x]
            plot coordinates {
                (5000, 287)
                (2500, 108)
                (1000, 48)
                (500, 27)
                (250, 14)
                (100, 6)
                (50, 3)
            };
        \addlegendentry{random 4-letter}

        \addplot[smooth,color=black,mark=+]
            plot coordinates {
                (5000, 457)
                (2500, 230)
                (1000, 84)
                (500, 44)
                (250, 23)
                (100, 10)
                (50, 5)
            };
        \addlegendentry{random 26-letter}

        \end{axis}
        \end{tikzpicture}
    \end{center}
    \caption{Длина текста около 500000 символов}
    \label{dna_time_stats1}
\end{figure}

Из графиков видно, что алгоритм действительно показывает большую эффективность для текстов над алфавитом из четырех букв. На текстах 26-буквенного алфавита алгоритм работает почти в два раза медленнее, чем на строках ДНК такой же длины.
При этом существенной разницы между временем работы на случайных текстах над четырехбуквенным алфавитом и на строках ДНК как правило не наблюдается. Из этого можно сделать вывод о том, что на фрагментах ДНК алгоритм работает быстрее именно за счет
небольшого размера алфавита, и специальная структура ДНК не имеет существенного влияния на скорость работы алгоритма.

На рис.\,\ref{real_vs_theor} показана зависимость между реальным временем работы алгоритма в секундах и функцией $n^2m$ из теоретической оценки времени работы алгоритма. Видно, что зависимость близка к линейной, то есть сравниваемые величины пропорциональны. Это позволяет утверждать что теоретическая оценка времени работы алгоритма подтверждается на практике.

\begin{figure}[H]
    \begin{center}
       \begin{tikzpicture}
        \begin{axis}[
            legend pos = north west,
            xlabel=$Time(sec)$,
            ylabel=$n^2 m$]
        \addplot[only marks,mark=*,black] 
            plot coordinates {
                (7297,  3.3781E+15)
                (2717,  1.80373E+15)
                (1105,  8.31367E+14)
                (550,   4.67548E+14)
                (263,   2.5548E+14)
                (100,   1.17943E+14)
                (48,    6.3774E+13)
                (1190,  5.01083E+14)
                (598,   2.77842E+14)
                (239,   1.29731E+14)
                (110,   7.13683E+13)
                (54,    3.9446E+13)
                (22,    1.78421E+13)
                (11,    1.01033E+13)
                (457,   1.6798E+14)
                (230,   9.41816E+13)
                (84,    4.34803E+13)
                (44,    2.38655E+13)
                (23,    1.30594E+13)
                (10,    6.29926E+12)
                (5, 3.63616E+12)
                (87,    2.70683E+13)
                (46,    1.48599E+13)
                (20,    6.77435E+12)
                (11,    3.71496E+12)
                (6, 2.11243E+12)
                (2, 1.01979E+12)
                (13, 2.34824E+12)
                (7, 1.29814E+12)
                (3, 5.87059E+11)
                (1, 3.41762E+11)
                (2, 3.55825E+11)
                (1, 1.97597E+11)
            };
        \addlegendentry{random 26-letter}

        \addplot[only marks, color=blue,  mark=x]
            plot coordinates {
                (1015, 9.21807E+13)
                (452, 5.03382E+13)
                (287, 2.31455E+13)
                (150, 1.27434E+13)
                (72, 7.19117E+12)
                (43, 3.37818E+12)
                (22, 2.04028E+12)
                (980, 9.42778E+13)
                (588, 5.15822E+13)
                (393, 2.37532E+13)
                (199, 1.3096E+13)
                (126, 7.3498E+12)
                (32, 3.54127E+12)
                (21, 2.0379E+12)
                (1176, 9.33064E+13)
                (548, 5.19176E+13)
                (224, 2.38959E+13)
                (128, 1.33342E+13)
                (76, 7.32721E+12)
                (22, 3.43257E+12)
                (15, 1.98033E+12)
                (537, 6.30871E+13)
                (332, 3.85956E+13)
                (200, 2.24671E+13)
                (118, 1.29758E+13)
                (65, 7.26779E+12)
                (33, 3.48456E+12)
                (18, 1.95799E+12)
                (3022, 3.47118E+14)
                (2493, 1.87259E+14)
                (1116, 8.45501E+13)
                (513, 4.75848E+13)
                (188, 2.63459E+13)
                (59, 1.23218E+13)
                (27, 6.89047E+12)
                (3552, 3.16474E+14)
                (1160, 1.7258E+14)
                (422, 7.75228E+13)
                (240, 4.30682E+13)
                (138, 2.39182E+13)
                (63, 1.0844E+13)
                (39, 6.1526E+12)
                (676, 8.54051E+13)
                (373, 4.6508E+13)
                (162, 2.13045E+13)
                (82, 1.21027E+13)
                (47, 6.73758E+12)
                (21, 3.27521E+12)
                (11, 1.96513E+12)
                (1742, 2.98658E+14)
                (805, 1.62E+14)
                (418, 7.27122E+13)
                (160, 4.02974E+13)
                (118, 2.2543E+13)
                (38, 1.03875E+13)
                (22, 5.89359E+12)
                (1089, 8.4457E+13)
                (405, 4.5833E+13)
                (193, 2.11298E+13)
                (101, 1.19632E+13)
                (48, 6.46323E+12)
                (18, 3.10732E+12)
                (10, 1.86439E+12)
                (2936, 2.88149E+14)
                (1466, 1.54681E+14)
                (579, 6.99698E+13)
                (225, 3.86883E+13)
                (113, 2.14296E+13)
                (44, 1.02114E+13)
                (22, 5.82482E+12)
                (574, 4.70983E+13)
                (258, 2.59677E+13)
                (110, 1.18872E+13)
                (63, 6.73672E+12)
                (29, 3.72086E+12)
                (11, 1.74293E+12)
                (5, 9.59591E+11)
                (2794, 2.72882E+14)
                (1448, 1.47736E+14)
                (506, 6.6533E+13)
                (241, 3.70546E+13)
                (118, 2.09379E+13)
                (44, 9.78022E+12)
                (22, 5.64773E+12)
                (870, 6.77789E+13)
                (405, 3.7951E+13)
                (143, 1.7281E+13)
                (84, 9.62358E+12)
                (39, 5.30331E+12)
                (16, 2.53524E+12)
                (8, 1.44871E+12)
                (360, 1.88155E+13)
                (167, 1.12519E+13)
                (78, 5.43871E+12)
                (40, 2.97678E+12)
                (18, 1.67561E+12)
                (7, 8.05042E+11)
                (3, 4.30604E+11)
                (2596, 2.30719E+14)
                (1234, 1.25538E+14)
                (491, 5.70629E+13)
                (154, 3.17085E+13)
                (95, 1.78283E+13)
                (37, 8.3281E+12)
                (18, 4.81179E+12)
                (1886, 1.62872E+14)
                (741, 9.10351E+13)
                (355, 4.18257E+13)
                (181, 2.27707E+13)
                (78, 1.23381E+13)
                (29, 5.66885E+12)
                (13, 3.23935E+12)
                (258, 1.13706E+13)
                (106, 6.50374E+12)
                (49, 3.02923E+12)
                (25, 1.68081E+12)
                (12, 9.40753E+11)
                (4, 4.26475E+11)
                (2, 2.44596E+11)
                (1343, 1.0102E+14)
                (594, 5.52097E+13)
                (225, 2.52637E+13)
                (115, 1.39072E+13)
                (58, 7.79225E+12)
                (21, 3.70394E+12)
                (12, 2.2014E+12)
                (1032, 7.54144E+13)
                (437, 4.04656E+13)
                (142, 1.85142E+13)
                (102, 1.03114E+13)
                (49, 5.97885E+12)
                (17, 2.7728E+12)
                (8, 1.5597E+12)
                (935, 6.50428E+13)
                (357, 3.52108E+13)
                (163, 1.5795E+13)
                (78, 8.44848E+12)
                (38, 4.85394E+12)
                (15, 2.38761E+12)
                (7, 1.36435E+12)
                (667, 4.43789E+13)
                (286, 2.46167E+13)
                (135, 1.1206E+13)
                (70, 6.1289E+12)
                (30, 3.37797E+12)
                (11, 1.55751E+12)
                (5, 9.10232E+11)
                (537, 3.05926E+13)
                (218, 1.66539E+13)
                (82, 7.43505E+12)
                (43, 4.05691E+12)
                (18, 2.22578E+12)
                (6, 1.04185E+12)
                (4, 6.31426E+11)
                (419, 2.14619E+13)
                (175, 1.18458E+13)
                (76, 5.48069E+12)
                (34, 2.98947E+12)
                (14, 1.60684E+12)
                (5, 7.84736E+11)
                (3, 4.85789E+11)
                (22, 7.50618E+11)
                (11, 4.16731E+11)
                (4, 1.92048E+11)
                (2, 1.11714E+11)
                (1, 64015916091)
                (0, 27614708902)
                (0, 10041712328)
                (23, 8.27728E+11)
                (12, 4.64172E+11)
                (4, 2.10621E+11)
                (2, 1.20738E+11)
                (1, 69759930708)
                (0, 34879965354)
                (7, 2.51849E+11)
                (4, 1.41554E+11)
                (1, 62519838376)
                (1, 35978397556)
                (1, 55641446154)
            };
        \addlegendentry{DNA}

        \end{axis}
        \end{tikzpicture}
    \end{center}
    \caption{Сравнение асимптотической оценки и реального времени работы алгоритма}
    \label{real_vs_theor}
\end{figure}

Отметим, что если выбирать в качестве параметра не длину текста, а длину ПП, порождающей этот текст, исследуемый алгоритм показывает лучший результат для текстов над 26-буквенным алфавитом. Это связано с тем, что тексты над четырехбуквенным алфавитом имеют большую степень сжатия и, как следствие, большую плотность непустых ячеек в таблице арифметических прогрессий. Это приводит к тому, что глубина рекурсии в процедуре LocalSearch для текстов с четырех буквенным алфавитом больше и соответственно больше константа в асимптотике времени работы.

В процессе реализации было выделено несколько моментов, которые потенциально могут вызывать чрезмерные затраты по времени
работы алгоритма.

Основной момент, дающий существенное замедление~--- рекурсивная процедура LocalSearch. Суммарное время выполнения вызовов этой процедуры составляет порядка $70\%$ времени работы алгоритма, а общее количество вызовов достигает порядка $10^{15}$. Исходя из того что рекурсивная реализация как правило уступает в эффективности нерекурсивному аналогу, можно предположить, что развертывание рекурсии окажется существенной оптимизацией.

Помимо этого, вспомним, что для вычисления значения в ячейке таблицы арифметических прогрессий $A[i, j]$ требуется чтобы были уже вычислены значения $A[f, 1] \dots A[f, j]$, $A[s, 1] \dots A[s, j]$, где $P_i \to P_fP_s$. То есть, для вычисления очередной ячейки достаточно знать значения в двух строках таблицы, соответствующих правилам, образующим $P_i$ (а точнее префиксов этих строк).

Такая ситуация приводит к мысли о том, что некоторые ячейки таблицы арифметических прогрессий можно вычислять параллельно.

Рассмотрим граф зависимостей ячеек таблицы. Каждому значению $A[i][j]$ соответствует вершина графа. 
Направленное ребро из вершины $A[i][j]$ в вершину $A[k][l]$ означает, что для вычисления значения 
в вершине $A[i][j]$ используется значение в вершине $A[k][l]$. Структура графа определяется 
видом ПП $P$ и $T$, поступающих на вход алгоритму. 
С точки зрения распараллеливания вычислений это означает, что значения в двух ячейках могут вычисляться 
параллельно тогда и только тогда, когда не существует направленного пути из одной вершины в другую.

Разумеется, эффективность распараллеливания существенно зависит от реализации, но анализ графа зависимостей 
позволяет дать разумную оценку эффективности. Мы будем оценивать две характеристики этого графа: максимальную длину пути и количество вершин, находящихся на расстоянии $s$ от листов дерева для различных $s$. 
Первая характеристика соответствует распараллеливанию с ``неограниченным'' числом потоков: если считать, что мы можем одновременно вычислять все значения, которые доступны в данный момент именно длина максимального пути соответствует времени работы алгоритма. Вторая характеристика в разумном смысле показывает, сколько потоков могут эффективно работать одновременно: количество потоков не должно превосходить количества вершин на большей части уровней. Строго говоря, такая оценка не вполне точна: вершины, находящиеся на более  высоком уровне не требуют для своей обработки готовности \emph{всех} вершин нижнего уровня, но нам представляется, что подобная оценка будет достаточно разумной. 

%Построить описанный граф не представляется возможным из-за большого размера таблицы арифметических прогрессий, поэтому была написана программа, которая определяет указанные характеристики графа без его явного построения, используя зависимости, сохраненные в ПП и метод динамического программирования.%

Были измерены указанные характеристики, ниже приведен результат для одного из тестов, в остальных
принципиальных отличий не наблюдается.

\begin{figure}[H]
    \begin{center}
    \begin{tabular}{ | c | c |}

    \hline
         Расстояние до листов & $Max Path Length = 12$  \\
          & $TextSlp Size = 14480$  \\
          & $PatternSlp Size = 416$  \\            
    \hline
    $1$ & $59568$ \\
    \hline
    $2$ & $231616$ \\
    \hline
    $3$ & $1621312$ \\
    \hline
    $4$ & $1795024$ \\
    \hline
    $5$ & $1056748$ \\
    \hline
    $6$ & $579040$ \\
    \hline
    $7$ & $303996$ \\
    \hline
    $8$ & $188188$ \\
    \hline
    $9$ & $86856$ \\
    \hline
    $10$ & $57904$ \\
    \hline
    $11$ & $28952$ \\
    \hline
    \end{tabular}
    \end{center}
    \caption{Количество вершин на фиксированном расстоянии от листов}
    \label{layers}
\end{figure}

Из результатов видно, что количество вершин на одном уровне значительно превышает количество потоков, которое разумно использовать при распараллеливании вычислений. Это означает, что без учета обмена данными между потоками, эффективность распараллеливания будет пропорциональна количеству потоков. 

Также, можно использовать подход, в котором ребра, входящие в вершину, удаляются после того, как значение в вершине было посчитано и стало доступно для использования. Вершина становится доступной для вычисления, если из нее не выходит ни одного ребра.

В качестве первого шага была реализована версия алгоритма с параллельными вычислениями, основанная на том, что ячейки таблицы, находящиеся в одной строке не зависят друг от друга, и, таким образом могут вычисляться параллельно (при условии что все предыдущие строки таблицы уже посчитаны).

Это простое распаралелливание дало на восьмиядерном процессоре ускорение в четыре раза. Ясно, что этот результат можно существенно улучшить за счет выбора более удачной стратегии распаралелливания.

\section{Заключение}

Не смотря на то, что теоретическая асимптотическая оценка времени работы алгоритма верна, реальное время работы оказывается довольно большим. Это связано с затратами на выполнение процедуры LocalSearch а так же на операции хеш-таблицы, в которой хранится таблица арифметических прогрессий. Возможно выбор других инструментов при реализации алгоритма позволит ускорить его работу.

В ходе реализации выяснилось, что алгоритм требует существенной оптимизации по памяти из-за огромных размеров таблицы арифметических прогрессий. Предложено решение этой проблемы, основанное на наблюдении о сильной разреженности таблицы. Практические тесты показывают высокую эффективность этого решения.

Также, было предложено несколько возможных оптимизаций алгоритма по времени. Самая существенная связана со вспомогательной рекурсивной процедурой LocalSearch, время исполнения которой занимает большую часть времени работы алгоритма. Было сделано предположение о том, что если прибегнуть к стандартной для таких случаев оптимизации --- развертыванию рекурсии, это позволит значительно уменьшить время работы алгоритма.

Была продемонстрирована зависимость эффективности алгоритма от размера алфавита, с которым он работает. 

Было выдвинуто и подтверждено предположение о том, что алгоритм Лифшица допускает распараллеливание, которое позволит значительно ускорить работу алгоритма.  

\begin{thebibliography}{99}

\bibitem{Lifshits}
\textsl{Yu. Lifshits}, Processing Compressed Texts: A Tractability Border.

\bibitem{1994}
\textsl{W. Plandowski}, Testing equivalence of morphisms on context-free languages. In
ESA'94, LNCS 855, pages 460470. Springer-Verlag, 1994.

\bibitem{1997}
\textsl{M. Miyazaki, A. Shinohara, and M. Takeda}, An improved pattern matching algorithm
for strings in terms of straight line programs. In CPM'97, LNCS 1264,
pages 111. Springer-Verlag, 1997.

\bibitem{usu}
\textsl{Бурмистров И. С., Козлова А. В., Курпилянский Е. Б., Хворост А. А.} Эффективное сжатие данных с помощью прямолинейных программ, Записки научных семинаров ПОМИ, RuFiDiM (2012), 45-68.

\bibitem{Ritter}
\textsl{W. Rytter}, Application of Lempel-Ziv factorization to the approximation of
grammar-based compression, Theor. Comput. Sci., 302 (2003), 211–222.

\bibitem{Huffman}
\textsl{D. Huffman},
A Method for the Construction of Minimum-Redundancy Codes Proceedings of the IRE, Vol. 40, No. 9. (1952), pp. 1098-1101 

\bibitem{anti}
\textsl{Y. Shibata, M. Takeda, A. Shinohara, S. Arikawa}, Pattern matching in text compressed by using antidictionaries, Lect. Notes Comput. Sci., 1645 (1999), 37–49.

\bibitem{Welch}
\textsl{T. Welch}, A technique for high-performance data compression, IEEE Computer, 17 (1984), 8–19.

\bibitem{LZ}
\textsl{J. Ziv, A. Lempel}, A universal algorithm for sequential data compression, IEEE Trans. Information Theory, 23 (1977), 337–343.

\end{thebibliography}

\end{document}